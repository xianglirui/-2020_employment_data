## 2020互联网就业数据展示分析

### 功能手册

#### 总叙

本项目通过可视化展示2020互联网就业数据，旨在直观形象描述今年的就业形势。本项目以前后端为技术骨架，连接起数据获取、数据存储、数据处理和数据展示几个核心功能。后端使用springboot框架，前端使用vue.js框架，ui组件以vant为主，可视化图表工具选择echarts，数据库选择mongodb，以python作为爬虫语言，用python相关的数据处理库完成主要的数据处理功能，但在特定场合下的数据处理需求由java和js分别完成。

前端代码和后端代码分别打包，以docker容器形式部署在阿里云服务器上

#### 登录

登录验证由jwt实现，登录成功后会在前端浏览器的cookie里存入两个变量，ROBOTCODE可以理解为一位用户的id，Token代表用户密码，交由jwt存储。前端采用request全局拦截器，在所有请求的请求头里塞入这两个变量，后端同样设置全局拦截器，获取Token并交由jwt进行比对，比对一致则放行，不一致返回状态码，前端设置response全局拦截器，根据状态码进行对应的路由操作。

因为登录验证依赖于cookie，所以不要禁用浏览器cookie。

#### 主页

首页是数据展示页面，可大致分为五大功能模块，包括：集搜索与导航功能的顶栏、地图模块、根据岗位条件筛选，将数据以柱状图和饼图展示、该职位在主流搜索引擎的搜索指数、提取该岗位的前十的技术要求。

##### 搜索功能

搜索功能一次发送五次请求，因为其中四个是四大模块的数据请求，下面会逐一讲解，所以在这里只讲解搜索请求

在搜索栏键入关键词点击搜索，后端收到请求后，首先查询数据库中有无符合要求的数据，有则从数据库中取出来；没有就调用爬虫，爬虫是以拉勾网为对象定制编写的。因为一次爬取的数据量较大，爬取时可能被对方检测到进行反爬打击或者将爬虫主机ip拉入黑名单，所以项目限制了单日爬虫调用次数，允许仅在当日的8-12点，14-18点这两个时间段各进行一次调用，在单个时间段只要有人调用一次爬虫，其余人便不能调用爬虫。

##### 岗位地图

岗位地图展示城市的岗位分布情况，技术简介如下：

当Home组件created时，会向后端发起获取岗位地图数据的请求，获得数据后传递给地图子组件，地图子组件在watch里监听数据变化并进行重新渲染。

为了方便多组件调用以及数据管理，城市信息用vuex保存。当切换城市时，会调用对城市信息处理的js文件，该文件根据vuex里的城市信息返回对应的城市信息json和js数据，地图组件根据返回的城市json与js数据将用户切换的城市渲染出来。

因为数据量有限，且爬虫有诸多限制，所以仅展示北京、上海、武汉三座城市。

##### 岗位筛选

该模块提供：工作经验、学历要求、公司规模、融资阶段四个筛选项。

柱状图：反映进行条件筛选后，月薪区间对应的岗位数。其中柱状部分代表单个筛选条件下，月薪对应的岗位数，折线部分代表符合四个条件，月薪对应的岗位数。

饼图：反映符合四项筛选条件，各月薪区间对应的岗位比例

技术简介：

该功能通过mongodb多条件查询取得数据，并通过java的map函数完成数据处理并返回给前端，前端请求回调传值，图表子组件通过watch更新渲染图表

##### 搜索趋势

因各大搜索引擎指数网站都做了反爬处理，综合工具网站提供的api有诸多限制且不完善，在个人精力有限的条件下，搜索指数数据由模拟算法生成，由springboot的定时任务完成数据的每日更新。

##### 技术要求

该模块功能简介如下：

根据城市和岗位两个请求参数，后端调用处理该数据功能的python脚本，将参数传递过去，脚本通过条件查询获取技术要求的文本列表，通过sklrean、numpy，jieba这三个工具库，提取出排名前十的技术要求，存储至数据库由springboot调用返回前端。

因为没有统一完善的词表，所以提取的关键词有很多没有意义，无关词例如code、web、windows，弱关键词例如html、css、js等基础技术。所以该数据集合有一个存储停用词的字段，用户如果发现前十的技术关键词里有如上无关词、弱关键词，可点击不合适按钮，后端接受请求后，将参数加入停用词列表字段，并调用python脚本，生成除开停用词外的十大技术词语。

#### 其他

本项目源码发布在码云，通过链接跳转到码云后会出现401页面，此时需要注册登录。

从url访问的安全角度考虑，项目的第三个页面——文档页面的路由并没有加入初始路由表，而是通过路由挂载的方式，在访问条件符合后，挂载到初始路由表上。也就是说该页面只能from home页面才能访问，刷新也会被拦截跳转到登录页面。

因为vue router本身的一些bug（也有可能是我还不知道的解决方法），异步挂载路由时，类似404、err这些公共的页面无法正常使用，所以本项目并未设置诸如404之类的表示请求错误的页面，加上异步路由一些小毛病，访问路由表以外的链接可能会出现空白页面，这个时候刷新一下就好了。

前后端代码通过docker分别部署至阿里云，在服务器环境下，会出现一些小毛病，例如访问较慢，请求超时会抛出异常，为此我将前端请求的超时时间延长，另外一个就是linux环境下java调用python脚本有些问题，还有一些不太典型的小毛病，我将尝试逐个解决。





